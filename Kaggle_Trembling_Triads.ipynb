{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ¤– Project Triad: Trembling Hand & Strategic Robustness\n",
                "\n",
                "This notebook runs the experiments for the paper **\"Trembling Hands and Hidden Coalitions\"**.\n",
                "It benchmarks LLM agents in 3-player games (PGG, Volunteer's Dilemma, Triadic PD) to analyze social intelligence and robustness against noise.\n",
                "\n",
                "**Repository:** [https://github.com/technoob05/Trembling-Triads](https://github.com/technoob05/Trembling-Triads)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment\n",
                "Clone the repository and install dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/technoob05/Trembling-Triads.git\n",
                "%cd Trembling-Triads\n",
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Models Check (H100 Ready)\n",
                "Supported Models in this benchmark:\n",
                "*   **Qwen2.5**: `Qwen2.5-7B`, `Qwen2.5-14B`, `Qwen2.5-32B`, `Qwen2.5-72B`\n",
                "*   **Llama 3**: `Llama3-8B`, `Llama3-70B`\n",
                "*   **DeepSeek R1**: `DeepSeek-R1-8B`, `DeepSeek-R1-70B`\n",
                "*   **Mistral**: `Mistral-7B`\n",
                "\n",
                "*(Note: 70B models require 2xT4 or 1xH100 GPU)*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Experiment A: The Scale Test (Small vs Large)\n",
                "Comparing Llama3-8B vs Llama3-70B in PGG with 5% Noise.\n",
                "Hypothesis: Larger models will show higher 'Trembling Robustness' (forgiveness)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Small Model\n",
                "!python triad_experiment.py --game PGG --models Llama3-8B --noise 0.05 --rounds 10\n",
                "\n",
                "# Run Large Model (Uncomment if GPU allows)\n",
                "# !python triad_experiment.py --game PGG --models Llama3-70B --noise 0.05 --rounds 10"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Experiment B: Volunteer's Dilemma\n",
                "Testing coordination capability with Qwen2.5-14B."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python triad_experiment.py --game VD --models Qwen2.5-14B --rounds 10"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Experiment C: Paper Metrics Export\n",
                "The Output JSON now contains granular data to calculate:\n",
                "*   **Survival Rate**: Check `strategy` sequence.\n",
                "*   **Trembling Robustness**: Compare `intended_strategy` vs `strategy` outcomes.\n",
                "*   **Payoff Gap**: Derived from `score`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import pandas as pd\n",
                "\n",
                "# Load Latest Results\n",
                "result_files = [f for f in os.listdir('.') if f.endswith('.json')]\n",
                "latest_file = max(result_files, key=os.path.getctime)\n",
                "\n",
                "with open(latest_file, 'r', encoding='utf-8') as f:\n",
                "    data = json.load(f)\n",
                "\n",
                "# Example: Parse Metrics\n",
                "print(\"Analyzing File:\", latest_file)\n",
                "for game_key, game_data in data.items():\n",
                "    if \"ERROR\" in game_key: continue\n",
                "    \n",
                "    history = game_data['history']\n",
                "    noise_events = 0\n",
                "    total_rounds = len(history)\n",
                "    \n",
                "    for round_name, agents in history.items():\n",
                "        for agent in agents:\n",
                "            if agent.get('is_noise'):\n",
                "                noise_events += 1\n",
                "                \n",
                "    print(f\"Game: {game_key} | Total Rounds: {total_rounds} | Noise Events Triggered: {noise_events}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}