# New Features: Reasoning Extraction & Meta-Prompting

## T·ªïng Quan

ƒê√£ th√™m 2 features m·ªõi theo paper **"Nicer than Human"**:

1. **Reasoning Extraction** - L∆∞u l√Ω do suy nghƒ© c·ªßa agent v√†o JSON
2. **Meta-Prompting** - Test xem agent c√≥ hi·ªÉu lu·∫≠t ch∆°i kh√¥ng

---

## Feature 1: Reasoning Extraction

### M√¥ T·∫£
Sau khi agent ch·ªçn strategy (Cooperate/Defect), h·ªá th·ªëng s·∫Ω h·ªèi th√™m m·ªôt c√¢u ri√™ng ƒë·ªÉ agent gi·∫£i th√≠ch **T·∫†I SAO** h·ªç ch·ªçn nh∆∞ v·∫≠y.

### C√°ch Ho·∫°t ƒê·ªông
1. Agent ch·ªçn strategy (prompt ng·∫Øn, max_new_tokens=10)
2. Sau khi parse strategy, h·ªá th·ªëng g·ª≠i th√™m reasoning prompt
3. Agent tr·∫£ l·ªùi reasoning (max_new_tokens tƒÉng l√™n)
4. Reasoning ƒë∆∞·ª£c l∆∞u v√†o JSON output

### Reasoning Prompt Example
```
You just chose to Cooperate in round 3 while playing with Bob, Charlie.
In 1-2 short sentences, explain WHY you made this choice. What factors influenced your decision?

Your reasoning:
```

### Output JSON Format
```json
{
  "round_1": [
    {
      "agent": "Alice",
      "strategy": "Cooperate",
      "intended_strategy": "Cooperate",
      "is_noise": false,
      "score": 7,
      "reasoning": "I cooperated because both opponents cooperated in the previous round, indicating a cooperative environment."
    }
  ]
}
```

### K√≠ch Ho·∫°t
```bash
# B·∫≠t reasoning extraction
python triad_experiment.py --game PD --models Qwen2.5-32B --rounds 5 --reasoning
```

### L∆∞u √ù
- Reasoning b·ªã limit ·ªü 300 k√Ω t·ª±
- N·∫øu kh√¥ng b·∫≠t `--reasoning`, reasoning field s·∫Ω l√† "Reasoning extraction disabled"
- Reasoning extraction l√†m tƒÉng th·ªùi gian ch·∫°y (th√™m 1 LLM call per agent per round)

---

## Feature 2: Meta-Prompting (Comprehension Validation)

### M√¥ T·∫£
ƒê·ªãnh k·ª≥ (·ªü c√°c round c·ª• th·ªÉ), h·ªá th·ªëng s·∫Ω h·ªèi agent c√°c c√¢u h·ªèi ƒë·ªÉ **ki·ªÉm tra xem agent c√≥ hi·ªÉu lu·∫≠t ch∆°i kh√¥ng**.

Theo paper "Nicer than Human", vi·ªác validate comprehension r·∫•t quan tr·ªçng ƒë·ªÉ ƒë·∫£m b·∫£o agent th·ª±c s·ª± hi·ªÉu game ch·ª© kh√¥ng ph·∫£i random guess.

### 3 Lo·∫°i Validation Questions

#### 1. Payoff Understanding
```
You are playing a game with payoffs. Answer briefly:
If you Cooperate and your opponent Defects, what happens to your score 
compared to if you both Cooperate?
Answer in one short sentence.
```

**M·ª•c ƒë√≠ch**: Test xem agent c√≥ hi·ªÉu payoff structure kh√¥ng

#### 2. History Recall
```
Based on the game history so far, which opponent has defected the most?
Answer with just the name or 'None'.
```

**M·ª•c ƒë√≠ch**: Test xem agent c√≥ theo d√µi ƒë∆∞·ª£c history kh√¥ng

#### 3. Strategy Understanding
```
What is your main goal in this game? Answer in one short sentence.
```

**M·ª•c ƒë√≠ch**: Test xem agent c√≥ hi·ªÉu objective c·ªßa game kh√¥ng

### Output JSON Format
```json
{
  "round_3": [
    {
      "agent": "Alice",
      "strategy": "Cooperate",
      "score": 7,
      "reasoning": "Bob always cooperates, so I trust him.",
      "meta_prompt_validation": {
        "payoff_understanding": "If I cooperate and opponent defects, I get lower score (sucker's payoff).",
        "history_recall": "Bob has not defected yet.",
        "strategy_understanding": "My goal is to maximize total points over all rounds."
      }
    }
  ]
}
```

### K√≠ch Ho·∫°t

**M·∫∑c ƒë·ªãnh**: T·∫Øt

```bash
# B·∫≠t meta-prompting ·ªü round 1, 3, 5
python triad_experiment.py --game PD --models Qwen2.5-32B --rounds 10 --meta-prompt

# T√πy ch·ªânh rounds cho meta-prompting
python triad_experiment.py --game PD --models Qwen2.5-32B --rounds 10 --meta-prompt --meta-rounds "1,5,10"

# K·∫øt h·ª£p c·∫£ reasoning v√† meta-prompting
python triad_experiment.py --game PD --models Qwen2.5-32B --rounds 10 --reasoning --meta-prompt
```

### L∆∞u √ù
- Meta-prompting ch·ªâ ch·∫°y ·ªü c√°c round ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
- M·ªói agent ƒë∆∞·ª£c h·ªèi 3 c√¢u h·ªèi
- C√°c c√¢u tr·∫£ l·ªùi b·ªã limit ·ªü 100 k√Ω t·ª±
- History recall ch·ªâ ƒë∆∞·ª£c h·ªèi t·ª´ round 2 tr·ªü ƒëi

---

## So S√°nh V·ªõi Paper "Nicer than Human"

| Feature | Paper "Nicer than Human" | Implementation N√†y |
|---------|-------------------------|-------------------|
| **Meta-Prompting** | ‚úÖ C√≥ | ‚úÖ C√≥ (`--meta-prompt`) |
| **Payoff Understanding** | ‚úÖ Test | ‚úÖ Test |
| **History Parsing** | ‚úÖ Test | ‚úÖ Test (History Recall) |
| **Strategy Understanding** | ‚úÖ Implicit | ‚úÖ Explicit question |
| **Reasoning Extraction** | ‚ùå Kh√¥ng c√≥ | ‚úÖ C√≥ (`--reasoning`) |
| **100-round games** | ‚úÖ C√≥ | ‚úÖ C√≥ (t√πy `--rounds`) |
| **Behavioral Dimensions** | ‚úÖ Ph√¢n t√≠ch | ‚è≥ Ch∆∞a (future work) |

---

## V√≠ D·ª• S·ª≠ D·ª•ng

### Experiment 1: Ch·ªâ Reasoning
```bash
python triad_experiment.py \
  --game PD \
  --models Qwen2.5-32B \
  --rounds 10 \
  --languages en \
  --reasoning
```

**Output**: JSON v·ªõi reasoning cho m·ªói round

---

### Experiment 2: Ch·ªâ Meta-Prompting
```bash
python triad_experiment.py \
  --game PD \
  --models "Qwen2.5-32B,Llama3-70B" \
  --rounds 20 \
  --meta-prompt \
  --meta-rounds "1,5,10,15,20"
```

**Output**: JSON v·ªõi validation results ·ªü round 1, 5, 10, 15, 20

---

### Experiment 3: Full Package (Gi·ªëng Paper)
```bash
python triad_experiment.py \
  --game PD \
  --models Qwen2.5-32B \
  --rounds 100 \
  --reasoning \
  --meta-prompt \
  --meta-rounds "1,10,25,50,75,100"
```

**Output**: 
- Reasoning cho t·∫•t c·∫£ 100 rounds
- Validation questions ·ªü 6 checkpoints
- Ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß behavior patterns

---

### Experiment 4: Test Comprehension Nhanh
```bash
# Test v·ªõi MockModel (kh√¥ng c·∫ßn GPU)
python triad_experiment.py \
  --game PGG \
  --models MockModel \
  --rounds 5 \
  --meta-prompt \
  --meta-rounds "1,3,5"
```

**M·ª•c ƒë√≠ch**: Test nhanh xem meta-prompting c√≥ ho·∫°t ƒë·ªông kh√¥ng

---

## Ph√¢n T√≠ch K·∫øt Qu·∫£

### Python Script ƒê·ªÉ Ph√¢n T√≠ch
```python
import json

with open('experiment_results_PD_1738014589.json', 'r') as f:
    data = json.load(f)

for exp_name, exp_data in data.items():
    print(f"\n{'='*60}")
    print(f"Experiment: {exp_name}")
    print(f"{'='*60}")
    
    history = exp_data['history']
    
    # Analyze reasoning patterns
    print("\n--- Reasoning Analysis ---")
    for round_key in sorted(history.keys()):
        round_data = history[round_key]
        print(f"\n{round_key}:")
        for agent_data in round_data:
            agent = agent_data['agent']
            strategy = agent_data['strategy']
            reasoning = agent_data.get('reasoning', 'N/A')
            print(f"  {agent} chose {strategy}")
            print(f"    Reasoning: {reasoning[:80]}...")
    
    # Analyze meta-prompt validations
    print("\n--- Meta-Prompt Validation ---")
    for round_key in sorted(history.keys()):
        round_data = history[round_key]
        for agent_data in round_data:
            if 'meta_prompt_validation' in agent_data:
                agent = agent_data['agent']
                meta = agent_data['meta_prompt_validation']
                print(f"\n{round_key} - {agent}:")
                print(f"  Payoff Understanding: {meta['payoff_understanding'][:60]}...")
                print(f"  History Recall: {meta['history_recall']}")
                print(f"  Strategy Understanding: {meta['strategy_understanding'][:60]}...")
```

---

## Performance Impact

| Feature | Extra LLM Calls per Round | Time Impact |
|---------|-------------------------|-------------|
| **Reasoning** | +3 (1 per agent) | ~3-5s extra |
| **Meta-Prompting** | +9 (3 questions √ó 3 agents) | ~10-15s extra |
| **Both** | +12 | ~15-20s extra |

**L∆∞u √Ω**: Ch·ªâ √°p d·ª•ng cho rounds c√≥ meta-prompting enabled

---

## Troubleshooting

### Q: Reasoning qu√° ng·∫Øn ho·∫∑c kh√¥ng c√≥ √Ω nghƒ©a?
**A**: Model c√≥ th·ªÉ c·∫ßn temperature cao h∆°n. Hi·ªán t·∫°i set `temperature=0.1` cho strategy nh∆∞ng reasoning prompt c√≥ th·ªÉ c·∫ßn ƒëi·ªÅu ch·ªânh.

### Q: Meta-prompt validation fail?
**A**: Agent c√≥ th·ªÉ kh√¥ng hi·ªÉu game. Xem output validation ƒë·ªÉ debug:
```python
# Check validation quality
meta = agent_data['meta_prompt_validation']
if 'lower' in meta['payoff_understanding'].lower():
    print("‚úì Agent understands payoff correctly")
else:
    print("‚úó Agent may not understand payoff")
```

### Q: C√≥ th·ªÉ extract reasoning m√† kh√¥ng c·∫ßn separate prompt kh√¥ng?
**A**: C√≥, nh∆∞ng s·∫Ω l√†m gi·∫£m accuracy c·ªßa strategy parsing. Separate prompt ƒë·∫£m b·∫£o:
1. Strategy parsing kh√¥ng b·ªã nhi·ªÖu
2. Reasoning ƒë·∫ßy ƒë·ªß h∆°n (kh√¥ng b·ªã limit b·ªüi max_new_tokens=10)

---

## Next Steps

C√°c features c√≥ th·ªÉ th√™m ti·∫øp theo:

1. **Behavioral Dimension Analysis**
   - T√≠nh cooperation rate
   - Detect strategy types (TFT, Always Defect, etc.)
   - Measure forgiveness, retaliation

2. **Adversarial Validation**
   - Test v·ªõi adversarial prompts
   - Check consistency across paraphrased questions

3. **Visualization**
   - Plot reasoning patterns over time
   - Visualize strategy evolution
   - Heatmap of cooperation/defection

4. **Auto Analysis**
   - T·ª± ƒë·ªông ph√¢n lo·∫°i reasoning (rule-based, reciprocal, etc.)
   - T·ª± ƒë·ªông grade meta-prompt answers

---

## T√†i Li·ªáu Tham Kh·∫£o

- **Paper**: "Nicer than Human: How Do Large Language Models Behave in the Prisoner's Dilemma?" (ICWSM 2025)
- **Code**: `triad_experiment.py` (d√≤ng 538-596 cho meta-prompting, d√≤ng 606-674 cho reasoning)

---

**Happy Experimenting! üéØ**

